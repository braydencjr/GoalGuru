{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/braydencjr/GoalGuru/blob/main/GoalGuru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF-8U-3pWrZx"
      },
      "source": [
        "##COMPLETE SMART CAREER ADVISOR - ENHANCED WITH DUAL SEARCH & USER MEMORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uQ7rv-kWv_S"
      },
      "source": [
        "Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06IHUgxGT8mg",
        "outputId": "2c7623fa-6bc5-4b32-c06e-8cd322d242e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-google-genai gradio googlesearch-python\n",
        "#Install Tavily for enhanced search results\n",
        "!pip install -q tavily-python\n",
        "\n",
        "import os, getpass\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Any, Optional\n",
        "from datetime import datetime\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o5nz-p6WoWJ"
      },
      "source": [
        "SET UP API KEYS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQCY4j2QWndN",
        "outputId": "846454ce-f802-4431-debb-54625e9a8a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë Enter your Gemini API key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "üîë Enter your TAVILY API key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Tavily search available\n"
          ]
        }
      ],
      "source": [
        "# Setup Gemini API Key\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"üîë Enter your Gemini API key:\")\n",
        "\n",
        "# Setup Tavily API Key (for better search results)\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"üîë Enter your TAVILY API key:\")\n",
        "\n",
        "# Import libraries with error handling\n",
        "try:\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain_core.messages import HumanMessage\n",
        "\n",
        "    llm_model = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "\n",
        "    from langchain.schema import HumanMessage\n",
        "    LLM_AVAILABLE = True\n",
        "\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è LangChain not available\")\n",
        "    LLM_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from googlesearch import search\n",
        "    GOOGLE_SEARCH_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Google search not available\")\n",
        "    GOOGLE_SEARCH_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from tavily import TavilyClient\n",
        "    TAVILY_AVAILABLE = bool(os.environ.get(\"TAVILY_API_KEY\", \"\").strip())\n",
        "    if TAVILY_AVAILABLE:\n",
        "        print(\"‚úÖ Tavily search available\")\n",
        "except ImportError:\n",
        "    TAVILY_AVAILABLE = False\n",
        "    print(\"üí° Install Tavily for enhanced search: pip install tavily-python\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PghF10NiWeh6"
      },
      "source": [
        "SET UP MEMORY SYSTEM WITH COMPLETE CONVERSATION TRACKING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k52yQamWde3"
      },
      "outputs": [],
      "source": [
        "class ConversationMemory:\n",
        "    \"\"\"Enhanced memory system with complete conversation history and smart filtering\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.sessions = {}\n",
        "\n",
        "    def get_session(self, session_id: str) -> Dict:\n",
        "        \"\"\"Get or create a session with enhanced fields\"\"\"\n",
        "        if session_id not in self.sessions:\n",
        "            self.sessions[session_id] = {\n",
        "                \"user_name\": \"\",\n",
        "                \"interests\": [],\n",
        "                \"skills\": [],\n",
        "                \"preferences\": [],\n",
        "                \"education_level\": \"unknown\",\n",
        "                \"conversation_history\": [],  # Store complete conversation context\n",
        "                \"suggested_careers\": [],\n",
        "                \"last_suggestions\": [],\n",
        "                \"searched_topics\": [],\n",
        "                \"favorite_careers\": [],\n",
        "                \"full_conversation\": [],  # Store all user messages and responses\n",
        "                \"key_facts\": [],  # Important facts mentioned by user\n",
        "                \"goals\": [],  # User's stated goals\n",
        "                \"concerns\": [],  # User's concerns or challenges\n",
        "                \"timeline\": \"\",  # When they plan to make decisions\n",
        "                \"location_preference\": \"\",  # Where they want to work/study\n",
        "                \"financial_situation\": \"\"  # Budget concerns, scholarship needs, etc.\n",
        "            }\n",
        "        return self.sessions[session_id]\n",
        "\n",
        "    def add_conversation_turn(self, session_id: str, user_message: str, bot_response: str):\n",
        "        \"\"\"Store complete conversation turn\"\"\"\n",
        "        session = self.get_session(session_id)\n",
        "        turn = {\n",
        "            \"timestamp\": str(datetime.now()),\n",
        "            \"user_message\": user_message,\n",
        "            \"bot_response\": bot_response\n",
        "        }\n",
        "        session[\"full_conversation\"].append(turn)\n",
        "\n",
        "        # Keep only last 20 turns to manage memory\n",
        "        if len(session[\"full_conversation\"]) > 20:\n",
        "            session[\"full_conversation\"] = session[\"full_conversation\"][-20:]\n",
        "\n",
        "    def add_search_topic(self, session_id: str, topic: str, query_type: str):\n",
        "        \"\"\"FIXED: Add the missing method to track search topics\"\"\"\n",
        "        session = self.get_session(session_id)\n",
        "        search_entry = f\"{topic} ({query_type})\"\n",
        "        if search_entry not in session[\"searched_topics\"]:\n",
        "            session[\"searched_topics\"].append(search_entry)\n",
        "\n",
        "        # Keep only last 10 searches\n",
        "        if len(session[\"searched_topics\"]) > 10:\n",
        "            session[\"searched_topics\"] = session[\"searched_topics\"][-10:]\n",
        "\n",
        "    def update_session(self, session_id: str, updates: Dict):\n",
        "        \"\"\"Update session data with smart merging\"\"\"\n",
        "        session = self.get_session(session_id)\n",
        "        for key, value in updates.items():\n",
        "            if key in [\"interests\", \"skills\", \"preferences\", \"searched_topics\", \"favorite_careers\", \"key_facts\", \"goals\", \"concerns\"] and isinstance(value, list):\n",
        "                # Merge lists without duplicates\n",
        "                existing = [item.lower() for item in session[key]]\n",
        "                for item in value:\n",
        "                    if item.lower() not in existing:\n",
        "                        session[key].append(item)\n",
        "            else:\n",
        "                session[key] = value\n",
        "\n",
        "memory = ConversationMemory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5obX0WTWRWI"
      },
      "source": [
        "Searching Mechanism With Smart Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQkUY9i9WQWH"
      },
      "outputs": [],
      "source": [
        "def intelligent_result_filtering(results: str, user_query: str, search_topic: str) -> str:\n",
        "    \"\"\"AI-powered intelligent filtering that adapts to any query without hardcoded rules\"\"\"\n",
        "\n",
        "    if not results or not search_topic:\n",
        "        return results\n",
        "\n",
        "    # Extract meaningful keywords from user query and search topic\n",
        "    import re\n",
        "\n",
        "    def extract_key_terms(text: str) -> List[str]:\n",
        "        \"\"\"Extract meaningful terms from text\"\"\"\n",
        "        # Remove common stop words\n",
        "        stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'what', 'where', 'when', 'how', 'why', 'about', 'tell', 'me', 'i', 'you', 'my', 'your'}\n",
        "\n",
        "        # Extract words longer than 2 characters\n",
        "        words = re.findall(r'\\b\\w{3,}\\b', text.lower())\n",
        "        meaningful_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "        # Also extract phrases (2-3 words together)\n",
        "        phrases = re.findall(r'\\b\\w+\\s+\\w+\\b', text.lower())\n",
        "        phrases += re.findall(r'\\b\\w+\\s+\\w+\\s+\\w+\\b', text.lower())\n",
        "\n",
        "        return meaningful_words + phrases\n",
        "\n",
        "    # Get key terms from both user query and search topic\n",
        "    query_terms = extract_key_terms(user_query)\n",
        "    topic_terms = extract_key_terms(search_topic)\n",
        "    all_key_terms = list(set(query_terms + topic_terms))\n",
        "\n",
        "    if not all_key_terms:\n",
        "        return results\n",
        "\n",
        "    # Split results into sections\n",
        "    sections = results.split(\"**\")\n",
        "    scored_sections = []\n",
        "\n",
        "    for i, section in enumerate(sections):\n",
        "        if i == 0:  # Always keep the header\n",
        "            scored_sections.append((section, 1000))  # High score for header\n",
        "            continue\n",
        "\n",
        "        section_lower = section.lower()\n",
        "        relevance_score = 0\n",
        "        matched_terms = []\n",
        "\n",
        "        # Score based on term matches\n",
        "        for term in all_key_terms:\n",
        "            if term in section_lower:\n",
        "                # Higher score for exact matches in titles/URLs\n",
        "                if term in section[:200].lower():  # First 200 chars (likely title/URL)\n",
        "                    relevance_score += 10\n",
        "                    matched_terms.append(term)\n",
        "                else:\n",
        "                    relevance_score += 5\n",
        "                    matched_terms.append(term)\n",
        "\n",
        "        # Bonus scoring for domain relevance\n",
        "        domain_indicators = {\n",
        "            'university': ['university', 'college', 'faculty', 'admission', 'course', 'program', 'degree', 'tuition', 'campus'],\n",
        "            'career': ['job', 'career', 'salary', 'employment', 'work', 'profession', 'hiring', 'skills'],\n",
        "            'company': ['company', 'corporation', 'business', 'employer', 'organization', 'firm']\n",
        "        }\n",
        "\n",
        "        for category, indicators in domain_indicators.items():\n",
        "            for indicator in indicators:\n",
        "                if indicator in section_lower:\n",
        "                    relevance_score += 2\n",
        "\n",
        "        # Store section with its score and matched terms\n",
        "        scored_sections.append((section, relevance_score, matched_terms))\n",
        "\n",
        "    # Sort by relevance score (descending)\n",
        "    scored_sections.sort(key=lambda x: x[1] if len(x) > 1 else 0, reverse=True)\n",
        "\n",
        "    # Determine filtering threshold\n",
        "    if len(scored_sections) > 1:\n",
        "        scores = [item[1] for item in scored_sections[1:]]  # Exclude header\n",
        "        if scores:\n",
        "            avg_score = sum(scores) / len(scores)\n",
        "            threshold = max(5, avg_score * 0.3)  # Dynamic threshold\n",
        "        else:\n",
        "            threshold = 5\n",
        "    else:\n",
        "        threshold = 0\n",
        "\n",
        "    # Filter sections based on relevance\n",
        "    filtered_sections = []\n",
        "    filtered_count = 0\n",
        "\n",
        "    for item in scored_sections:\n",
        "        section = item[0]\n",
        "        score = item[1] if len(item) > 1 else 1000\n",
        "\n",
        "        if score >= threshold or filtered_count == 0:  # Always keep header + relevant sections\n",
        "            filtered_sections.append(section)\n",
        "            if score < 1000:  # Don't count header\n",
        "                filtered_count += 1\n",
        "\n",
        "        if filtered_count >= 4:\n",
        "            break\n",
        "\n",
        "    # If we filtered out too much, be more lenient\n",
        "    if filtered_count < 2 and len(scored_sections) > 3:\n",
        "        filtered_sections = [item[0] for item in scored_sections[:5]]  # Take top 5 including header\n",
        "        filtering_note = f\"\\n\\nüí° *Showing broader results for '{search_topic}' - some may be partially relevant.*\"\n",
        "    else:\n",
        "        filtering_note = f\"\\n\\n‚úÖ *Results intelligently filtered for: {search_topic}*\"\n",
        "\n",
        "    filtered_result = \"**\".join(filtered_sections)\n",
        "\n",
        "    # Add filtering explanation\n",
        "    if filtered_count > 0:\n",
        "        filtered_result += filtering_note\n",
        "\n",
        "    return filtered_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ABiZlwsWFev"
      },
      "source": [
        "DUAL SEARCH SYSTEM (Tavily + Google Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJR2b9tsWBrM"
      },
      "outputs": [],
      "source": [
        "def search_with_google(query: str) -> Optional[str]:\n",
        "    if not GOOGLE_SEARCH_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        results = []\n",
        "        for url in search(query, num_results=4):\n",
        "            results.append(url)\n",
        "\n",
        "        if results:\n",
        "            return \"üìã **Related Resources:**\\n\" + \"\\n\".join([f\"‚Ä¢ {url}\" for url in results])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Google search error: {e}\")\n",
        "        return None\n",
        "\n",
        "def search_with_tavily(query: str, search_type: str = \"general\", user_query: str = \"\", search_topic: str = \"\") -> Optional[str]:\n",
        "    \"\"\"Enhanced search using Tavily API with smart filtering\"\"\"\n",
        "    if not TAVILY_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        tavily_key = os.environ.get(\"TAVILY_API_KEY\", \"\").strip()\n",
        "        if not tavily_key or tavily_key == \"YOUR_TAVILY_API_KEY_HERE\":\n",
        "            return None\n",
        "\n",
        "        client = TavilyClient(api_key=tavily_key)\n",
        "\n",
        "        # Enhanced search with more specific targeting\n",
        "        response = client.search(\n",
        "            query=query,\n",
        "            search_depth=\"advanced\",\n",
        "            max_results=6,  # Get more results for better filtering\n",
        "            include_domains=[\n",
        "                \"jobstreet.com.my\", \"linkedin.com\", \"glassdoor.com\",\n",
        "                \"says.com\", \"studymalaysia.com\", \"afterschool.my\",\n",
        "                \"qswur.com\", \"universitiesmalaysia.my\", \"um.edu.my\",\n",
        "                \"utm.my\", \"upm.edu.my\", \"ukm.my\", \"usm.my\"\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if response.get(\"results\"):\n",
        "            formatted_results = \"\"\n",
        "            for i, result in enumerate(response[\"results\"][:4], 1):  # Show top 4\n",
        "                title = result.get(\"title\", \"\")\n",
        "                content = result.get(\"content\", \"\")\n",
        "                url = result.get(\"url\", \"\")\n",
        "\n",
        "                # Extract key information based on search type\n",
        "                if search_type == \"salary\" and any(word in content.lower() for word in [\"rm\", \"ringgit\", \"salary\", \"pay\"]):\n",
        "                    content = content[:300] + \"...\"\n",
        "                elif search_type == \"university\" and any(word in content.lower() for word in [\"university\", \"college\", \"tuition\", \"fee\"]):\n",
        "                    content = content[:300] + \"...\"\n",
        "                else:\n",
        "                    content = content[:250] + \"...\"\n",
        "\n",
        "                formatted_results += f\"**{i}. {title}**\\n{content}\\nüîó [Read more]({url})\\n\\n\"\n",
        "\n",
        "            # Use the intelligent filtering\n",
        "            filtered_results = intelligent_result_filtering(formatted_results, user_query, search_topic)\n",
        "            return filtered_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Tavily search error: {e}\")\n",
        "        return None\n",
        "\n",
        "def smart_career_search(topic: str, query_type: str, session_id: str, user_query: str = \"\") -> str:\n",
        "    \"\"\"Intelligent search with enhanced filtering - FIXED\"\"\"\n",
        "\n",
        "    # Track what user is searching for - FIXED: Now calls the correct method\n",
        "    memory.add_search_topic(session_id, topic, query_type)\n",
        "\n",
        "    # Craft more specific queries based on type and topic\n",
        "    queries = {\n",
        "        \"salary\": f\"{topic} average salary Malaysia 2024 jobstreet glassdoor\",\n",
        "        \"tuition\": f\"{topic} university course tuition fees Malaysia 2024\",\n",
        "        \"ranking\": f\"best {topic} universities Malaysia ranking QS Times\",\n",
        "        \"companies\": f\"top companies hiring {topic} Malaysia multinational\",\n",
        "        \"requirements\": f\"{topic} job requirements skills qualifications Malaysia\",\n",
        "        \"prospects\": f\"{topic} career prospects job market Malaysia future\",\n",
        "        \"pathway\": f\"how to become {topic} Malaysia education pathway steps\",\n",
        "        \"general\": f\"{topic} career information Malaysia opportunities\"\n",
        "    }\n",
        "\n",
        "    # Special handling for university-specific queries\n",
        "    if any(uni in topic.lower() for uni in [\"universiti malaya\", \"utm\", \"upm\", \"ukm\", \"usm\", \"um\"]):\n",
        "        queries[\"tuition\"] = f\"{topic} tuition fees courses programs Malaysia\"\n",
        "        queries[\"ranking\"] = f\"{topic} ranking programs courses Malaysia\"\n",
        "        queries[\"general\"] = f\"{topic} courses programs admission requirements Malaysia\"\n",
        "\n",
        "    search_query = queries.get(query_type, queries[\"general\"])\n",
        "    result_header = f\"üîç **{query_type.title()} Information for {topic}:**\\n\\n\"\n",
        "\n",
        "    # Try Tavily first with enhanced filtering\n",
        "    tavily_result = search_with_tavily(search_query, query_type, user_query, topic)\n",
        "    if tavily_result:\n",
        "        return result_header + tavily_result\n",
        "\n",
        "    # Fallback to Google search\n",
        "    google_result = search_with_google(search_query)\n",
        "    if google_result:\n",
        "        return result_header + google_result\n",
        "\n",
        "    # If both fail\n",
        "    return f\"üîç I couldn't find current information about {topic} ({query_type}) right now. Please try again later.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sbf02m-V90v"
      },
      "source": [
        "# ENHANCED LLM LOGIC WITH COMPLETE MEMORY INTEGRATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCTVLme1V5a3"
      },
      "outputs": [],
      "source": [
        "def enhanced_career_analysis(user_input: str, session_id: str) -> Dict:\n",
        "    \"\"\"Enhanced analysis with complete conversation memory\"\"\"\n",
        "\n",
        "    if not LLM_AVAILABLE:\n",
        "        return {\n",
        "            \"is_career_related\": True,\n",
        "            \"user_name\": \"\",\n",
        "            \"new_interests\": [],\n",
        "            \"new_skills\": [],\n",
        "            \"new_preferences\": [],\n",
        "            \"education_level\": \"unknown\",\n",
        "            \"response\": \"I'm having trouble connecting to the AI service. Please check your API key.\",\n",
        "            \"suggestions\": [],\n",
        "            \"search_requests\": [],\n",
        "            \"follow_up_question\": None\n",
        "        }\n",
        "\n",
        "    session = memory.get_session(session_id)\n",
        "\n",
        "    # Build comprehensive profile with complete conversation history\n",
        "    recent_conversation = \"\"\n",
        "    if session[\"full_conversation\"]:\n",
        "        recent_conversation = \"\\n\".join([\n",
        "            f\"User: {turn['user_message']}\\nBot: {turn['bot_response'][:200]}...\"\n",
        "            for turn in session[\"full_conversation\"][-3:]  # Last 3 turns\n",
        "        ])\n",
        "\n",
        "    profile_summary = f\"\"\"\n",
        "    User Name: {session['user_name'] or 'Unknown'}\n",
        "    Interests: {session['interests']}\n",
        "    Skills: {session['skills']}\n",
        "    Preferences: {session['preferences']}\n",
        "    Education Level: {session['education_level']}\n",
        "    Goals: {session['goals']}\n",
        "    Concerns: {session['concerns']}\n",
        "    Key Facts: {session['key_facts']}\n",
        "    Timeline: {session['timeline']}\n",
        "    Location Preference: {session['location_preference']}\n",
        "    Financial Situation: {session['financial_situation']}\n",
        "    Previous Suggestions: {session['last_suggestions']}\n",
        "    Previously Searched: {session['searched_topics']}\n",
        "    Favorite Careers: {session['favorite_careers']}\n",
        "\n",
        "    Recent Conversation Context:\n",
        "    {recent_conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    # Enhanced prompt with complete context awareness\n",
        "    prompt = f\"\"\"\n",
        "You are GoalGuru, a smart and friendly AI career advisor for Malaysian users.\n",
        "You have complete memory of the conversation and can understand context deeply.\n",
        "\n",
        "User's current message: \"{user_input}\"\n",
        "\n",
        "Complete User Profile & Context: {profile_summary}\n",
        "\n",
        "Your enhanced tasks:\n",
        "\n",
        "1. **Complete Context Understanding**: Use ALL conversation history to provide contextual responses.\n",
        "\n",
        "2. **Name Recognition**: Extract name if mentioned.\n",
        "\n",
        "3. **Enhanced Search Detection**: Detect if user wants specific information and identify the EXACT entity:\n",
        "   - For universities: Extract the specific university name (e.g., \"Universiti Malaya\", \"UTM\")\n",
        "   - For careers: Extract the specific career/field\n",
        "   - For companies: Extract the specific company name\n",
        "   - Query types: salary|tuition|ranking|companies|requirements|prospects|pathway|general\n",
        "\n",
        "4. **Complete Memory Updates**: Extract ANY new information about the user:\n",
        "   - Personal facts, family background, constraints\n",
        "   - Goals, dreams, concerns, fears\n",
        "   - Timeline preferences, location preferences\n",
        "   - Financial situation, scholarship needs\n",
        "   - Academic performance, extracurricular activities\n",
        "\n",
        "5. **Contextual Career Guidance**: Use complete conversation history for better suggestions.\n",
        "\n",
        "Respond in this JSON format:\n",
        "{{\n",
        "  \"is_career_related\": true or false,\n",
        "  \"user_name\": \"extracted name or empty string\",\n",
        "  \"new_interests\": [\"any new interests mentioned\"],\n",
        "  \"new_skills\": [\"any new skills mentioned\"],\n",
        "  \"new_preferences\": [\"any new preferences mentioned\"],\n",
        "  \"new_goals\": [\"any goals or aspirations mentioned\"],\n",
        "  \"new_concerns\": [\"any concerns or challenges mentioned\"],\n",
        "  \"new_key_facts\": [\"any important personal facts\"],\n",
        "  \"timeline\": \"when they plan to make decisions\",\n",
        "  \"location_preference\": \"where they want to work/study\",\n",
        "  \"financial_situation\": \"budget concerns, scholarship needs\",\n",
        "  \"education_level\": \"secondary|pre-university|undergraduate|graduate|working|unknown\",\n",
        "  \"response\": \"Contextual response using conversation history and their name\",\n",
        "  \"suggestions\": [\n",
        "    {{\n",
        "      \"career\": \"Career Name\",\n",
        "      \"reason\": \"Why this fits based on complete profile and conversation\",\n",
        "      \"path\": {{\n",
        "        \"pre_university\": \"Program name\",\n",
        "        \"university_course\": \"Course name\",\n",
        "        \"example_universities\": [\"UM\", \"UTM\", \"UKM\"],\n",
        "        \"scholarships\": [\"JPA\", \"MARA\", \"Yayasan Khazanah\"]\n",
        "      }},\n",
        "      \"next_steps\": \"Actionable steps based on their situation\"\n",
        "    }}\n",
        "  ],\n",
        "  \"search_requests\": [\n",
        "    {{\n",
        "      \"topic\": \"EXACT entity name (e.g., 'Universiti Malaya', 'Data Scientist')\",\n",
        "      \"query_type\": \"salary|tuition|ranking|companies|requirements|prospects|pathway|general\"\n",
        "    }}\n",
        "  ],\n",
        "  \"follow_up_question\": \"Contextual question based on conversation history\"\n",
        "}}\n",
        "\n",
        "IMPORTANT:\n",
        "- For search requests, be very specific with the \"topic\" field\n",
        "- Use complete conversation context to provide better responses\n",
        "- Remember and reference previous parts of the conversation\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = llm_model.invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "        # Extract JSON\n",
        "        match = re.search(r\"{.*}\", response.content, re.DOTALL)\n",
        "        if match:\n",
        "            parsed = json.loads(match.group())\n",
        "\n",
        "            # Update memory with complete information\n",
        "            updates = {}\n",
        "            if parsed.get(\"user_name\"):\n",
        "                updates[\"user_name\"] = parsed[\"user_name\"]\n",
        "            if parsed.get(\"new_interests\"):\n",
        "                updates[\"interests\"] = session[\"interests\"] + parsed[\"new_interests\"]\n",
        "            if parsed.get(\"new_skills\"):\n",
        "                updates[\"skills\"] = session[\"skills\"] + parsed[\"new_skills\"]\n",
        "            if parsed.get(\"new_preferences\"):\n",
        "                updates[\"preferences\"] = session[\"preferences\"] + parsed[\"new_preferences\"]\n",
        "            if parsed.get(\"new_goals\"):\n",
        "                updates[\"goals\"] = session[\"goals\"] + parsed[\"new_goals\"]\n",
        "            if parsed.get(\"new_concerns\"):\n",
        "                updates[\"concerns\"] = session[\"concerns\"] + parsed[\"new_concerns\"]\n",
        "            if parsed.get(\"new_key_facts\"):\n",
        "                updates[\"key_facts\"] = session[\"key_facts\"] + parsed[\"new_key_facts\"]\n",
        "            if parsed.get(\"timeline\"):\n",
        "                updates[\"timeline\"] = parsed[\"timeline\"]\n",
        "            if parsed.get(\"location_preference\"):\n",
        "                updates[\"location_preference\"] = parsed[\"location_preference\"]\n",
        "            if parsed.get(\"financial_situation\"):\n",
        "                updates[\"financial_situation\"] = parsed[\"financial_situation\"]\n",
        "            if parsed.get(\"education_level\") != \"unknown\":\n",
        "                updates[\"education_level\"] = parsed[\"education_level\"]\n",
        "            if parsed.get(\"suggestions\"):\n",
        "                updates[\"last_suggestions\"] = [s[\"career\"] for s in parsed[\"suggestions\"]]\n",
        "                updates[\"favorite_careers\"] = session[\"favorite_careers\"] + [s[\"career\"] for s in parsed[\"suggestions\"]]\n",
        "\n",
        "            memory.update_session(session_id, updates)\n",
        "\n",
        "            return parsed\n",
        "        else:\n",
        "            raise json.JSONDecodeError(\"No JSON found\", response.content, 0)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå LLM error: {e}\")\n",
        "        return {\n",
        "            \"is_career_related\": False,\n",
        "            \"user_name\": \"\",\n",
        "            \"new_interests\": [],\n",
        "            \"new_skills\": [],\n",
        "            \"new_preferences\": [],\n",
        "            \"education_level\": \"unknown\",\n",
        "            \"response\": \"I'm here to help with your career questions! What would you like to know?\",\n",
        "            \"suggestions\": [],\n",
        "            \"search_requests\": [],\n",
        "            \"follow_up_question\": None\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS68olFEVxuS"
      },
      "source": [
        "ENHANCED CHATBOT WITH COMPLETE MEMORY AND SMART FILTERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khmMQSsAVusk"
      },
      "outputs": [],
      "source": [
        "def enhanced_chatbot_with_detailed_search(user_input: str, chat_history: List, session_id: str):\n",
        "    \"\"\"Enhanced chatbot with complete memory and smart search filtering - FIXED\"\"\"\n",
        "\n",
        "    chat_history = chat_history or []\n",
        "    session = memory.get_session(session_id)\n",
        "\n",
        "    # Get AI analysis\n",
        "    result = enhanced_career_analysis(user_input, session_id)\n",
        "\n",
        "    # Build personalized response with conversation context\n",
        "    user_name = session.get(\"user_name\", \"\")\n",
        "    greeting = f\"Hi {user_name}! \" if user_name else \"\"\n",
        "\n",
        "    ai_response = result.get(\"response\", \"Thanks for sharing!\")\n",
        "    if greeting and not ai_response.startswith(\"Hi\") and user_name:\n",
        "        ai_response = greeting + ai_response\n",
        "\n",
        "    suggestions = result.get(\"suggestions\", [])\n",
        "    search_requests = result.get(\"search_requests\", [])\n",
        "\n",
        "    # Handle search requests with enhanced filtering\n",
        "    if search_requests:\n",
        "        ai_response += \"\\n\\n\" + \"=\"*50 + \"\\n\"\n",
        "        for search_req in search_requests:\n",
        "            topic = search_req.get(\"topic\", \"\")\n",
        "            query_type = search_req.get(\"query_type\", \"general\")\n",
        "\n",
        "            if topic:\n",
        "                # Pass the original user query for better filtering\n",
        "                search_result = smart_career_search(topic, query_type, session_id, user_input)\n",
        "                ai_response += f\"\\n{search_result}\\n\" + \"=\"*50 + \"\\n\"\n",
        "\n",
        "    # Add career suggestions with complete context\n",
        "    if suggestions:\n",
        "        ai_response += f\"\\n\\nüéØ **Career Suggestions{f' for {user_name}' if user_name else ''}:**\\n\"\n",
        "        for i, suggestion in enumerate(suggestions, 1):\n",
        "            ai_response += f\"\\n**{i}. {suggestion.get('career', 'Unknown')}**\"\n",
        "            ai_response += f\"\\nüí° {suggestion.get('reason', '')}\"\n",
        "\n",
        "            # Add detailed pathway\n",
        "            path = suggestion.get(\"path\", {})\n",
        "            if path and any(path.values()):\n",
        "                ai_response += f\"\\n\\nüìò **Study Path:**\"\n",
        "                if path.get(\"pre_university\"):\n",
        "                    ai_response += f\"\\n‚Ä¢ Pre-University: {path['pre_university']}\"\n",
        "                if path.get(\"university_course\"):\n",
        "                    ai_response += f\"\\n‚Ä¢ University Course: {path['university_course']}\"\n",
        "                if path.get(\"example_universities\"):\n",
        "                    ai_response += f\"\\n‚Ä¢ Universities: {', '.join(path['example_universities'])}\"\n",
        "                if path.get(\"scholarships\"):\n",
        "                    ai_response += f\"\\n‚Ä¢ Scholarships: {', '.join(path['scholarships'])}\"\n",
        "\n",
        "            if suggestion.get(\"next_steps\"):\n",
        "                ai_response += f\"\\nüéØ **Next Steps:** {suggestion['next_steps']}\"\n",
        "\n",
        "            ai_response += \"\\n\"\n",
        "\n",
        "    # Add follow-up question\n",
        "    follow_up = result.get(\"follow_up_question\")\n",
        "    if follow_up:\n",
        "        ai_response += f\"\\n‚ùì {follow_up}\"\n",
        "\n",
        "    # Show enhanced memory context\n",
        "    if any([session[\"interests\"], session[\"skills\"], user_name, session[\"goals\"], session[\"key_facts\"]]):\n",
        "        ai_response += f\"\\n\\nüí≠ **What I remember{f' about {user_name}' if user_name else ''}:**\"\n",
        "        if user_name:\n",
        "            ai_response += f\"\\n‚Ä¢ Name: {user_name}\"\n",
        "        if session[\"interests\"]:\n",
        "            ai_response += f\"\\n‚Ä¢ Interests: {', '.join(session['interests'][-5:])}\"  # Last 5\n",
        "        if session[\"skills\"]:\n",
        "            ai_response += f\"\\n‚Ä¢ Skills: {', '.join(session['skills'][-5:])}\"\n",
        "        if session[\"goals\"]:\n",
        "            ai_response += f\"\\n‚Ä¢ Goals: {', '.join(session['goals'][-3:])}\"\n",
        "        if session[\"key_facts\"]:\n",
        "            ai_response += f\"\\n‚Ä¢ Key Facts: {', '.join(session['key_facts'][-3:])}\"\n",
        "        if session[\"education_level\"] != \"unknown\":\n",
        "            ai_response += f\"\\n‚Ä¢ Education: {session['education_level']}\"\n",
        "        if session[\"timeline\"]:\n",
        "            ai_response += f\"\\n‚Ä¢ Timeline: {session['timeline']}\"\n",
        "\n",
        "    # Store complete conversation turn\n",
        "    memory.add_conversation_turn(session_id, user_input, ai_response.strip())\n",
        "\n",
        "    chat_history.append((user_input, ai_response.strip()))\n",
        "    return chat_history, chat_history, \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laWoyYtXVkl6"
      },
      "source": [
        "Build User Interface Using Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhwz25RjVj0P",
        "outputId": "52e39c09-5377-4ffa-849e-f0a83fa7bd01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Building enhanced Gradio interface...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4177814379.py:45: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-4177814379.py:45: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        }
      ],
      "source": [
        "def initialize_enhanced_chat():\n",
        "    \"\"\"Initialize with enhanced greeting\"\"\"\n",
        "    search_status = \"‚úÖ Tavily + Google\" if TAVILY_AVAILABLE else \"‚úÖ Google Search\" if GOOGLE_SEARCH_AVAILABLE else \"‚ùå Search Disabled\"\n",
        "\n",
        "    initial_message = [\n",
        "        (None, f\"\"\"üëã **Welcome to GoalGuru - Your Smart Career Advisor!**\n",
        "\n",
        "üÜï **Enhanced Features:**\n",
        "‚Ä¢ **Personal Memory**: I remember your name and preferences\n",
        "‚Ä¢ **Detailed Search**: Ask about salaries, tuition fees, university rankings, top companies\n",
        "‚Ä¢ **Smart Recommendations**: Personalized career suggestions\n",
        "‚Ä¢ **Study Pathways**: Complete education roadmaps\n",
        "\n",
        "üîç **Search Status**: {search_status}\n",
        "\n",
        "üéØ **Tell me:**\n",
        "‚Ä¢ Your name (I'll remember it!)\n",
        "‚Ä¢ Your interests, skills, education level\n",
        "‚Ä¢ Ask specific questions like:\n",
        "  - \"What's the salary for data scientists in Malaysia?\"\n",
        "  - \"Which universities have the best engineering programs?\"\n",
        "  - \"What are the tuition fees for computer science?\"\n",
        "  - \"Which companies hire accountants?\"\n",
        "\n",
        "üí° **Example**: \"Hi, I'm Sarah. I love math and I'm in Form 5. What's the salary for engineers?\"\n",
        "\n",
        "What would you like to explore today?\"\"\")\n",
        "    ]\n",
        "    return initial_message\n",
        "\n",
        "# Build Enhanced Gradio Interface\n",
        "print(\"üöÄ Building enhanced Gradio interface...\")\n",
        "\n",
        "with gr.Blocks(title=\"GoalGuru - Enhanced Career Advisor\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üéì GoalGuru: Smart Career Advisor\")\n",
        "    gr.Markdown(\"*Enhanced with Personal Memory, Dual Search & Detailed Queries*\")\n",
        "\n",
        "    with gr.Row():\n",
        "        session_input = gr.Textbox(\n",
        "            label=\"üîë Session ID\",\n",
        "            value=\"user_0001\",\n",
        "            info=\"Keep the same ID to maintain your personal profile and memory\"\n",
        "        )\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        label=\"üí¨ Chat with GoalGuru\",\n",
        "        bubble_full_width=False,\n",
        "        value=initialize_enhanced_chat(),\n",
        "        height=600\n",
        "    )\n",
        "\n",
        "    state = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Introduce yourself, ask about careers, salaries, universities, or search for specific information...\",\n",
        "            scale=4,\n",
        "            container=False,\n",
        "            label=\"Your Message\"\n",
        "        )\n",
        "        send_btn = gr.Button(\"Send\", scale=1, variant=\"primary\")\n",
        "\n",
        "    # Event handlers\n",
        "    send_btn.click(\n",
        "        fn=enhanced_chatbot_with_detailed_search,\n",
        "        inputs=[msg, state, session_input],\n",
        "        outputs=[chatbot, state, msg]\n",
        "    )\n",
        "\n",
        "    msg.submit(\n",
        "        fn=enhanced_chatbot_with_detailed_search,\n",
        "        inputs=[msg, state, session_input],\n",
        "        outputs=[chatbot, state, msg]\n",
        "    )\n",
        "\n",
        "    # Enhanced examples\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"Hi, I'm Alex. I love programming and I'm in Form 5\"],\n",
        "            [\"What's the average salary for data scientists in Malaysia?\"],\n",
        "            [\"Which universities have the best computer science programs?\"],\n",
        "            [\"What are the tuition fees for engineering courses?\"],\n",
        "            [\"Which companies hire marketing graduates?\"],\n",
        "            [\"How do I become a doctor? What are the requirements?\"],\n",
        "            [\"What's the job prospects for AI engineers?\"]\n",
        "        ],\n",
        "        inputs=msg\n",
        "    )\n",
        "\n",
        "    # Status information\n",
        "    with gr.Row():\n",
        "        gr.Markdown(f\"\"\"\n",
        "        **System Status:**\n",
        "        - ü§ñ LLM: {'‚úÖ Connected' if LLM_AVAILABLE else '‚ùå Check API Key'}\n",
        "        - üîç Tavily Search: {'‚úÖ Available' if TAVILY_AVAILABLE else '‚ö†Ô∏è Not configured (optional)'}\n",
        "        - üåê Google Search: {'‚úÖ Available' if GOOGLE_SEARCH_AVAILABLE else '‚ùå Not available'}\n",
        "        \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2EjeKEOVcLG"
      },
      "source": [
        "LAUNCH THE ENHANCED APP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "UGN-zH1CVbtu",
        "outputId": "3d46079a-b721-4303-e027-cda81b5d95fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Enhanced GoalGuru setup complete!\n",
            "üîç Search capabilities: Tavily + Google\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f79d6c9bd4d2a219ad.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://f79d6c9bd4d2a219ad.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        }
      ],
      "source": [
        "print(\"‚úÖ Enhanced GoalGuru setup complete!\")\n",
        "print(f\"üîç Search capabilities: {'Tavily + Google' if TAVILY_AVAILABLE else 'Google only' if GOOGLE_SEARCH_AVAILABLE else 'Limited'}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)\n",
        "else:\n",
        "    demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtBHy//RpawS4T0+qnX4mE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}